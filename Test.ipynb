{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c33da27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email sent successfully !\n",
      "From: youssefkhalifa@51talk.com\n",
      "Subject: Test from Python\n",
      "Submission is done successfully !\n",
      "Recieved !\n"
     ]
    }
   ],
   "source": [
    "import smtplib\n",
    "from email.message import EmailMessage\n",
    "import config\n",
    "import imaplib, email\n",
    "from time import sleep\n",
    "\n",
    "def Send_email():\n",
    "\n",
    "    config.PASSWORD\n",
    "    msg = EmailMessage()\n",
    "    msg[\"Subject\"] = \"Test from Python\"\n",
    "    msg[\"From\"] = config.EMAIL\n",
    "    msg[\"To\"] = \"youssefkhalifa@51talk.com\"\n",
    "    msg.set_content(\"Submission is done successfully !\")\n",
    "\n",
    "    with smtplib.SMTP_SSL(config.SMTP_HOST, config.SMTP_PORT) as smtp:\n",
    "        smtp.login(config.EMAIL, config.Pass_email)\n",
    "        smtp.send_message(msg)\n",
    "    print('Email sent successfully !')\n",
    "\n",
    "def Check_for_mail():\n",
    "    \n",
    "    with imaplib.IMAP4_SSL(config.IMAP_HOST, config.IMAP_PORT) as imap:\n",
    "        imap.login(config.EMAIL, config.PASSWORD)\n",
    "        imap.select(\"INBOX\")  # or another folder\n",
    "        status, data = imap.search(None, 'UNSEEN')  # e.g., unseen messages\n",
    "        for num in data[0].split():\n",
    "            status, msg_data = imap.fetch(num, \"(RFC822)\")\n",
    "            msg = email.message_from_bytes(msg_data[0][1])\n",
    "            print(\"From:\", msg.get(\"From\"))\n",
    "            print(\"Subject:\", msg.get(\"Subject\"))\n",
    "            # If the email is multipart, pull out the first text/plain part\n",
    "            if msg.is_multipart():\n",
    "                for part in msg.walk():\n",
    "                    if part.get_content_type() == \"text/plain\":\n",
    "                        print(part.get_payload(decode=True).decode(part.get_content_charset() or \"utf-8\"))\n",
    "                        break\n",
    "            else:\n",
    "                print(msg.get_payload(decode=True).decode(msg.get_content_charset() or \"utf-8\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d150ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, Column, Integer, String, Numeric, text\n",
    "from sqlalchemy.orm import DeclarativeBase, sessionmaker, Mapped, mapped_column\n",
    "from datetime import datetime\n",
    "\n",
    "# engine (uses psycopg)\n",
    "engine = create_engine(\"postgresql+psycopg://postgres:postgres@localhost:5432/appdb\", echo=False)\n",
    "\n",
    "class Base(DeclarativeBase):\n",
    "    pass\n",
    "\n",
    "class Widget(Base):\n",
    "    __tablename__ = \"widgets\"\n",
    "    id: Mapped[int] = mapped_column(Integer, primary_key=True)\n",
    "    name: Mapped[str] = mapped_column(String, nullable=False)\n",
    "    price: Mapped[float] = mapped_column(Numeric(10,2), nullable=False)\n",
    "\n",
    "# create tables\n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "Session = sessionmaker(bind=engine)\n",
    "with Session() as s:\n",
    "    # create\n",
    "    w = Widget(name=\"doodad\", price=14.50)\n",
    "    s.add(w)\n",
    "    s.commit()\n",
    "    s.refresh(w)\n",
    "    print(\"Inserted:\", w.id)\n",
    "\n",
    "    # read\n",
    "    recent = s.query(Widget).order_by(Widget.id.desc()).limit(5).all()\n",
    "    for r in recent:\n",
    "        print(r.id, r.name, r.price)\n",
    "\n",
    "    # raw SQL when you want it\n",
    "    for (now,) in s.execute(text(\"SELECT now()\")):\n",
    "        print(now)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6e7fb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database ready ✅\n"
     ]
    }
   ],
   "source": [
    "# create_db_then_run.py\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.exc import ProgrammingError\n",
    "\n",
    "PG_USER = \"postgres\"              # your superuser (or a role with CREATEDB)\n",
    "PG_PASS = \"123\"         # <-- put the real password here\n",
    "PG_HOST = \"localhost\"\n",
    "PG_PORT = 5432\n",
    "APP_DB  = \"appdb\"\n",
    "\n",
    "# 1) Connect to the built-in 'postgres' database as admin\n",
    "admin_url = f\"postgresql+psycopg://{PG_USER}:{PG_PASS}@{PG_HOST}:{PG_PORT}/postgres\"\n",
    "admin_engine = create_engine(admin_url, isolation_level=\"AUTOCOMMIT\")\n",
    "\n",
    "with admin_engine.connect() as conn:\n",
    "    exists = conn.execute(\n",
    "        text(\"SELECT 1 FROM pg_database WHERE datname = :n\"),\n",
    "        {\"n\": APP_DB},\n",
    "    ).scalar()\n",
    "    if not exists:\n",
    "        conn.execute(text(f\"CREATE DATABASE {APP_DB}\"))\n",
    "        # Optionally assign an owner:\n",
    "        # conn.execute(text(f\"ALTER DATABASE {APP_DB} OWNER TO {PG_USER}\"))\n",
    "\n",
    "# 2) Now connect to your actual app database\n",
    "app_url = f\"postgresql+psycopg://{PG_USER}:{PG_PASS}@{PG_HOST}:{PG_PORT}/{APP_DB}\"\n",
    "app_engine = create_engine(app_url)\n",
    "\n",
    "print(\"Database ready ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cc9fa41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission: 2 Alice Ahmed\n",
      "in_probation: True\n",
      "notice_period_days: 45\n",
      "created_at: 2025-10-29 13:34:17.703922+03:00 updated_at: 2025-10-29 13:34:17.703922+03:00\n",
      "updated_at after update: 2025-10-29 13:34:17.721702+03:00\n"
     ]
    }
   ],
   "source": [
    "# file: hr_copilot_models.py\n",
    "from datetime import date, datetime  # add datetime\n",
    "from typing import Optional\n",
    "from sqlalchemy import (\n",
    "    create_engine, text, MetaData, Table, Index, DDL, event,\n",
    "    Integer, String, Boolean, Date, TIMESTAMP, func, ForeignKey, Computed, Text, UniqueConstraint\n",
    ")\n",
    "from sqlalchemy.dialects import postgresql as psql\n",
    "from sqlalchemy.orm import DeclarativeBase, mapped_column, Mapped, relationship, Session\n",
    "from sqlalchemy.schema import ForeignKeyConstraint\n",
    "\n",
    "\n",
    "# ---- 0) Engine ----\n",
    "# Adjust to your settings\n",
    "DATABASE_URL = \"postgresql+psycopg://postgres:123@localhost:5432/appdb\"\n",
    "engine = create_engine(DATABASE_URL, echo=False, future=True)\n",
    "\n",
    "# ---- 1) Bootstrap objects that must exist before tables ----\n",
    "# Create role_t enum type if missing (safe via DO/EXCEPTION)\n",
    "BOOTSTRAP_ENUM = \"\"\"\n",
    "DO $$\n",
    "BEGIN\n",
    "  CREATE TYPE role_t AS ENUM ('super_user','hr','leader','chm','it','admin');\n",
    "EXCEPTION WHEN duplicate_object THEN NULL;\n",
    "END $$;\n",
    "\"\"\"\n",
    "\n",
    "# Create/replace the set_updated_at() trigger function\n",
    "BOOTSTRAP_FUNC = \"\"\"\n",
    "CREATE OR REPLACE FUNCTION set_updated_at() RETURNS trigger AS $$\n",
    "BEGIN\n",
    "  NEW.updated_at := now();\n",
    "  RETURN NEW;\n",
    "END;\n",
    "$$ LANGUAGE plpgsql;\n",
    "\"\"\"\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    conn.exec_driver_sql(BOOTSTRAP_ENUM)\n",
    "    conn.exec_driver_sql(BOOTSTRAP_FUNC)\n",
    "\n",
    "# We’ll reference the already-created PostgreSQL enum\n",
    "role_t = psql.ENUM(\n",
    "    \"super_user\",\"hr\",\"leader\",\"chm\",\"it\",\"admin\",\n",
    "    name=\"role_t\", create_type=False\n",
    ")\n",
    "\n",
    "# ---- 2) ORM models / metadata ----\n",
    "class Base(DeclarativeBase):\n",
    "    metadata = MetaData()\n",
    "\n",
    "class User(Base):\n",
    "    __tablename__ = \"users\"\n",
    "\n",
    "    id: Mapped[int] = mapped_column(Integer, primary_key=True)\n",
    "    email: Mapped[str] = mapped_column(String(150), unique=True, nullable=False)\n",
    "    full_name: Mapped[str] = mapped_column(String(120), nullable=False)\n",
    "    role: Mapped[str] = mapped_column(role_t, nullable=False)\n",
    "    password_hash: Mapped[Optional[str]] = mapped_column(String, nullable=True)\n",
    "    is_active: Mapped[bool] = mapped_column(Boolean, nullable=False, server_default=text(\"TRUE\"))\n",
    "    created_at: Mapped[datetime] = mapped_column(TIMESTAMP(timezone=True), nullable=False, server_default=func.now())\n",
    "    hashed_password = mapped_column(String, nullable=False)\n",
    "\n",
    "\n",
    "class Submission(Base):\n",
    "    __tablename__ = \"submissions\"\n",
    "\n",
    "    id: Mapped[int] = mapped_column(Integer, primary_key=True)\n",
    "\n",
    "    employee_name: Mapped[str] = mapped_column(String(100), nullable=False)\n",
    "    employee_email: Mapped[str] = mapped_column(String(150), nullable=False)\n",
    "\n",
    "    joining_date: Mapped[date] = mapped_column(Date, nullable=False)\n",
    "    submission_date: Mapped[date] = mapped_column(Date, nullable=False, server_default=text(\"CURRENT_DATE\"))\n",
    "    last_working_day: Mapped[date] = mapped_column(Date, nullable=False)\n",
    "\n",
    "    resignation_status: Mapped[str] = mapped_column(String(30), nullable=False, server_default=text(\"'submitted'\"))\n",
    "    team_leader_reply: Mapped[Optional[bool]] = mapped_column(Boolean)\n",
    "    team_leader_notes: Mapped[Optional[str]] = mapped_column(Text)  # Text is fine for notes\n",
    "    chinese_head_reply: Mapped[Optional[bool]] = mapped_column(Boolean)\n",
    "    chinese_head_notes: Mapped[Optional[str]] = mapped_column(Text)\n",
    "\n",
    "    exit_interview_status: Mapped[str] = mapped_column(String(30), nullable=False, server_default=text(\"'not_scheduled'\"))\n",
    "    exit_interview_notes: Mapped[Optional[str]] = mapped_column(Text)\n",
    "\n",
    "    it_support_reply: Mapped[Optional[bool]] = mapped_column(Boolean)\n",
    "\n",
    "    vendor_mail_sent: Mapped[bool] = mapped_column(Boolean, nullable=False, server_default=text(\"FALSE\"))\n",
    "    medical_card_collected: Mapped[bool] = mapped_column(Boolean, nullable=False, server_default=text(\"FALSE\"))\n",
    "\n",
    "    in_probation: Mapped[bool] = mapped_column(\n",
    "        Boolean, Computed(\"(submission_date - joining_date) < 90\", persisted=True)\n",
    "    )\n",
    "    notice_period_days: Mapped[int] = mapped_column(\n",
    "        Integer, Computed(\"(last_working_day - submission_date)\", persisted=True)\n",
    "    )\n",
    "\n",
    "    created_at: Mapped[datetime] = mapped_column(TIMESTAMP(timezone=True), nullable=False, server_default=func.now())\n",
    "    updated_at: Mapped[datetime] = mapped_column(TIMESTAMP(timezone=True), nullable=False, server_default=func.now())\n",
    "\n",
    "    assets: Mapped[\"Assets\"] = relationship(\n",
    "        back_populates=\"submission\", uselist=False, cascade=\"all, delete-orphan\", passive_deletes=True\n",
    "    )\n",
    "\n",
    "    __table_args__ = (\n",
    "        Index(\"idx_submissions_status\", \"resignation_status\"),\n",
    "        Index(\"idx_submissions_employee_eml\", \"employee_email\"),\n",
    "    )\n",
    "\n",
    "\n",
    "class Assets(Base):\n",
    "    __tablename__ = \"assets\"\n",
    "\n",
    "    id: Mapped[int] = mapped_column(Integer, primary_key=True)\n",
    "    res_id: Mapped[int] = mapped_column(Integer, nullable=False)\n",
    "\n",
    "    laptop: Mapped[Optional[bool]] = mapped_column(Boolean)\n",
    "    mouse: Mapped[Optional[bool]] = mapped_column(Boolean)\n",
    "    headphones: Mapped[Optional[bool]] = mapped_column(Boolean)\n",
    "    others: Mapped[Optional[str]] = mapped_column(Text)\n",
    "    approved: Mapped[Optional[bool]] = mapped_column(Boolean)\n",
    "\n",
    "    created_at: Mapped[datetime] = mapped_column(TIMESTAMP(timezone=True), nullable=False, server_default=func.now())\n",
    "    updated_at: Mapped[datetime] = mapped_column(TIMESTAMP(timezone=True), nullable=False, server_default=func.now())\n",
    "\n",
    "    __table_args__ = (\n",
    "        ForeignKeyConstraint([\"res_id\"], [\"submissions.id\"], deferrable=True, initially=\"DEFERRED\"),\n",
    "        UniqueConstraint(\"res_id\", name=\"uq_assets_res_id\"),  # enforces one-to-one at DB level\n",
    "        Index(\"idx_assets_res_id\", \"res_id\"),\n",
    "    )\n",
    "\n",
    "    submission: Mapped[\"Submission\"] = relationship(back_populates=\"assets\", single_parent=True)\n",
    "\n",
    "\n",
    "# ---- 3) Create tables ----\n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "# ---- 4) Triggers: keep updated_at fresh on UPDATE (matches your DDL) ----\n",
    "# Drop+Create triggers for submissions\n",
    "submissions_tbl: Table = Submission.__table__\n",
    "assets_tbl: Table = Assets.__table__\n",
    "\n",
    "trg_drop_create_submissions = DDL(\"\"\"\n",
    "DROP TRIGGER IF EXISTS trg_submissions_updated ON submissions;\n",
    "CREATE TRIGGER trg_submissions_updated\n",
    "BEFORE UPDATE ON submissions\n",
    "FOR EACH ROW EXECUTE FUNCTION set_updated_at();\n",
    "\"\"\")\n",
    "\n",
    "trg_drop_create_assets = DDL(\"\"\"\n",
    "DROP TRIGGER IF EXISTS trg_assets_updated ON assets;\n",
    "CREATE TRIGGER trg_assets_updated\n",
    "BEFORE UPDATE ON assets\n",
    "FOR EACH ROW EXECUTE FUNCTION set_updated_at();\n",
    "\"\"\")\n",
    "\n",
    "# Ensure triggers exist after (re)creating tables\n",
    "event.listen(submissions_tbl, \"after_create\", trg_drop_create_submissions)\n",
    "event.listen(assets_tbl, \"after_create\", trg_drop_create_assets)\n",
    "\n",
    "# (Re-)run the trigger DDL now that tables exist\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(\"DROP TRIGGER IF EXISTS trg_submissions_updated ON submissions\"))\n",
    "    conn.execute(text(\"CREATE TRIGGER trg_submissions_updated BEFORE UPDATE ON submissions FOR EACH ROW EXECUTE FUNCTION set_updated_at()\"))\n",
    "    conn.execute(text(\"DROP TRIGGER IF EXISTS trg_assets_updated ON assets\"))\n",
    "    conn.execute(text(\"CREATE TRIGGER trg_assets_updated BEFORE UPDATE ON assets FOR EACH ROW EXECUTE FUNCTION set_updated_at()\"))\n",
    "\n",
    "# ---- 5) Tiny demo: insert / query / see generated columns ----\n",
    "if __name__ == \"__main__\":\n",
    "    with Session(engine) as s:\n",
    "        # create a submission\n",
    "        sub = Submission(\n",
    "            employee_name=\"Alice Ahmed\",\n",
    "            employee_email=\"alice@example.com\",\n",
    "            joining_date=date(2025, 8, 1),\n",
    "            submission_date=date(2025, 10, 1),\n",
    "            last_working_day=date(2025, 11, 15),\n",
    "            resignation_status=\"submitted\"\n",
    "        )\n",
    "        s.add(sub)\n",
    "        s.flush()  # get sub.id\n",
    "\n",
    "        # add assets (one-to-one)\n",
    "        assets = Assets(res_id=sub.id, laptop=True, mouse=True, headphones=False, approved=None, others=\"Returned badge\")\n",
    "        s.add(assets)\n",
    "        s.commit()\n",
    "\n",
    "        # query + show generated columns and timestamps\n",
    "        fresh = s.get(Submission, sub.id)\n",
    "        print(\"Submission:\", fresh.id, fresh.employee_name)\n",
    "        print(\"in_probation:\", fresh.in_probation)          # boolean from generated column\n",
    "        print(\"notice_period_days:\", fresh.notice_period_days)\n",
    "        print(\"created_at:\", fresh.created_at, \"updated_at:\", fresh.updated_at)\n",
    "\n",
    "        # trigger demo: update notes -> updated_at changes\n",
    "        fresh.team_leader_notes = \"Looks good.\"\n",
    "        s.commit()\n",
    "        s.refresh(fresh)\n",
    "        print(\"updated_at after update:\", fresh.updated_at)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ae0cfac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'Alice Ahmed', 'alice@example.com', datetime.date(2025, 8, 1), datetime.date(2025, 10, 1), datetime.date(2025, 11, 15), 'submitted', None, 'Looks good.', None, None, 'not_scheduled', None, None, False, False, True, 45, datetime.datetime(2025, 10, 29, 11, 55, 42, 814308, tzinfo=zoneinfo.ZoneInfo(key='Africa/Cairo')), datetime.datetime(2025, 10, 29, 11, 55, 42, 829791, tzinfo=zoneinfo.ZoneInfo(key='Africa/Cairo')), None)\n",
      "(2, 'Alice Ahmed', 'alice@example.com', datetime.date(2025, 8, 1), datetime.date(2025, 10, 1), datetime.date(2025, 11, 15), 'submitted', None, 'Looks good.', None, None, 'not_scheduled', None, None, False, False, True, 45, datetime.datetime(2025, 10, 29, 13, 34, 17, 703922, tzinfo=zoneinfo.ZoneInfo(key='Africa/Cairo')), datetime.datetime(2025, 10, 29, 13, 34, 17, 721702, tzinfo=zoneinfo.ZoneInfo(key='Africa/Cairo')), None)\n",
      "(29, 'Workflow Test Employee 1761835431', 'workflowtest_1761835431@company.com', datetime.date(2024, 1, 1), datetime.date(2024, 10, 30), datetime.date(2024, 12, 31), 'submitted', None, None, None, None, 'not_scheduled', None, None, False, False, False, 62, datetime.datetime(2025, 10, 30, 17, 43, 53, 620548, tzinfo=zoneinfo.ZoneInfo(key='Africa/Cairo')), datetime.datetime(2025, 10, 30, 17, 43, 53, 620548, tzinfo=zoneinfo.ZoneInfo(key='Africa/Cairo')), None)\n",
      "(30, 'Workflow Test Employee 1761835984', 'workflowtest_1761835984@company.com', datetime.date(2024, 1, 1), datetime.date(2024, 10, 30), datetime.date(2024, 12, 31), 'submitted', None, None, None, None, 'not_scheduled', None, None, False, False, False, 62, datetime.datetime(2025, 10, 30, 17, 53, 6, 836099, tzinfo=zoneinfo.ZoneInfo(key='Africa/Cairo')), datetime.datetime(2025, 10, 30, 17, 53, 6, 836099, tzinfo=zoneinfo.ZoneInfo(key='Africa/Cairo')), None)\n",
      "(31, 'Workflow Test Employee 1761839374', 'workflowtest_1761839374@company.com', datetime.date(2024, 1, 1), datetime.date(2024, 10, 30), datetime.date(2024, 12, 31), 'submitted', None, None, None, None, 'not_scheduled', None, None, False, False, False, 62, datetime.datetime(2025, 10, 30, 18, 49, 36, 511969, tzinfo=zoneinfo.ZoneInfo(key='Africa/Cairo')), datetime.datetime(2025, 10, 30, 18, 49, 36, 511969, tzinfo=zoneinfo.ZoneInfo(key='Africa/Cairo')), None)\n",
      "(32, 'Workflow Test Employee 1761839417', 'workflowtest_1761839417@company.com', datetime.date(2024, 1, 1), datetime.date(2024, 10, 30), datetime.date(2024, 12, 31), 'submitted', None, None, None, None, 'not_scheduled', None, None, False, False, False, 62, datetime.datetime(2025, 10, 30, 18, 50, 19, 604901, tzinfo=zoneinfo.ZoneInfo(key='Africa/Cairo')), datetime.datetime(2025, 10, 30, 18, 50, 19, 604901, tzinfo=zoneinfo.ZoneInfo(key='Africa/Cairo')), None)\n",
      "(33, 'Workflow Test Employee 1761840035', 'workflowtest_1761840035@company.com', datetime.date(2024, 1, 1), datetime.date(2024, 10, 30), datetime.date(2024, 12, 31), 'submitted', None, None, None, None, 'not_scheduled', None, None, False, False, False, 62, datetime.datetime(2025, 10, 30, 19, 0, 37, 588607, tzinfo=zoneinfo.ZoneInfo(key='Africa/Cairo')), datetime.datetime(2025, 10, 30, 19, 0, 37, 588607, tzinfo=zoneinfo.ZoneInfo(key='Africa/Cairo')), None)\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "DATABASE_URL = \"postgresql+psycopg://postgres:123@localhost:5432/appdb\"\n",
    "engine = create_engine(DATABASE_URL, echo=False, future=True)\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"SELECT * FROM submissions\"))\n",
    "    rows = result.fetchall()       # or .fetchone() / .scalars()\n",
    "    for row in rows:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "097512fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "employee_name\n",
      "employee_email\n",
      "joining_date\n",
      "submission_date\n",
      "last_working_day\n",
      "resignation_status\n",
      "team_leader_reply\n",
      "team_leader_notes\n",
      "chinese_head_reply\n",
      "chinese_head_notes\n",
      "exit_interview_status\n",
      "exit_interview_notes\n",
      "it_support_reply\n",
      "vendor_mail_sent\n",
      "medical_card_collected\n",
      "in_probation\n",
      "notice_period_days\n",
      "created_at\n",
      "updated_at\n",
      "last_reminded_at\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import inspect\n",
    "\n",
    "inspector = inspect(engine)\n",
    "for column in inspector.get_columns(\"submissions\", schema=\"public\"):\n",
    "    print(column[\"name\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5c55be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HR_Resignation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
