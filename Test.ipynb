{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c33da27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email sent successfully !\n"
     ]
    }
   ],
   "source": [
    "import smtplib\n",
    "from email.message import EmailMessage\n",
    "import config\n",
    "import imaplib, email\n",
    "from time import sleep\n",
    "\n",
    "def Send_email(mail = \"youssefkhalifa@51talk.com\"):\n",
    "\n",
    "    msg = EmailMessage()\n",
    "    msg[\"Subject\"] = \"Test from Python\"\n",
    "    msg[\"From\"] = config.EMAIL\n",
    "    msg[\"To\"] = mail\n",
    "    msg.set_content(\"Submission is done successfully !\")\n",
    "\n",
    "    with smtplib.SMTP_SSL(config.SMTP_HOST, config.SMTP_PORT) as smtp:\n",
    "        smtp.login(config.EMAIL, config.PASSWORD)\n",
    "        smtp.send_message(msg)\n",
    "    print('Email sent successfully !')\n",
    "\n",
    "def Check_for_mail():\n",
    "    \n",
    "    with imaplib.IMAP4_SSL(config.IMAP_HOST, config.IMAP_PORT) as imap:\n",
    "        imap.login(config.EMAIL, config.PASSWORD)\n",
    "        imap.select(\"INBOX\")  # or another folder\n",
    "        status, data = imap.search(None, 'UNSEEN')  # e.g., unseen messages\n",
    "        for num in data[0].split():\n",
    "            status, msg_data = imap.fetch(num, \"(RFC822)\")\n",
    "            msg = email.message_from_bytes(msg_data[0][1])\n",
    "            print(\"From:\", msg.get(\"From\"))\n",
    "            print(\"Subject:\", msg.get(\"Subject\"))\n",
    "            # If the email is multipart, pull out the first text/plain part\n",
    "            if msg.is_multipart():\n",
    "                for part in msg.walk():\n",
    "                    if part.get_content_type() == \"text/plain\":\n",
    "                        print(part.get_payload(decode=True).decode(part.get_content_charset() or \"utf-8\"))\n",
    "                        break\n",
    "            else:\n",
    "                print(msg.get_payload(decode=True).decode(msg.get_content_charset() or \"utf-8\"))\n",
    "\n",
    "Send_email(mail=\"youssefkhalifa458@gmail.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2199393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df =pd.read_excel('Assets/Team Mapping & Contacts.xlsx')\n",
    "df.to_csv('Assets/Team Mapping & Contacts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d150ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, Column, Integer, String, Numeric, text\n",
    "from sqlalchemy.orm import DeclarativeBase, sessionmaker, Mapped, mapped_column\n",
    "from datetime import datetime\n",
    "\n",
    "# engine (uses psycopg)\n",
    "engine = create_engine(\"postgresql+psycopg://postgres:postgres@localhost:5432/appdb\", echo=False)\n",
    "\n",
    "class Base(DeclarativeBase):\n",
    "    pass\n",
    "\n",
    "class Widget(Base):\n",
    "    __tablename__ = \"widgets\"\n",
    "    id: Mapped[int] = mapped_column(Integer, primary_key=True)\n",
    "    name: Mapped[str] = mapped_column(String, nullable=False)\n",
    "    price: Mapped[float] = mapped_column(Numeric(10,2), nullable=False)\n",
    "\n",
    "# create tables\n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "Session = sessionmaker(bind=engine)\n",
    "with Session() as s:\n",
    "    # create\n",
    "    w = Widget(name=\"doodad\", price=14.50)\n",
    "    s.add(w)\n",
    "    s.commit()\n",
    "    s.refresh(w)\n",
    "    print(\"Inserted:\", w.id)\n",
    "\n",
    "    # read\n",
    "    recent = s.query(Widget).order_by(Widget.id.desc()).limit(5).all()\n",
    "    for r in recent:\n",
    "        print(r.id, r.name, r.price)\n",
    "\n",
    "    # raw SQL when you want it\n",
    "    for (now,) in s.execute(text(\"SELECT now()\")):\n",
    "        print(now)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6e7fb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database ready ‚úÖ\n"
     ]
    }
   ],
   "source": [
    "# create_db_then_run.py\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.exc import ProgrammingError\n",
    "\n",
    "PG_USER = \"postgres\"              # your superuser (or a role with CREATEDB)\n",
    "PG_PASS = \"123\"         # <-- put the real password here\n",
    "PG_HOST = \"localhost\"\n",
    "PG_PORT = 5432\n",
    "APP_DB  = \"appdb\"\n",
    "\n",
    "# 1) Connect to the built-in 'postgres' database as admin\n",
    "admin_url = f\"postgresql+psycopg://{PG_USER}:{PG_PASS}@{PG_HOST}:{PG_PORT}/postgres\"\n",
    "admin_engine = create_engine(admin_url, isolation_level=\"AUTOCOMMIT\")\n",
    "\n",
    "with admin_engine.connect() as conn:\n",
    "    exists = conn.execute(\n",
    "        text(\"SELECT 1 FROM pg_database WHERE datname = :n\"),\n",
    "        {\"n\": APP_DB},\n",
    "    ).scalar()\n",
    "    if not exists:\n",
    "        conn.execute(text(f\"CREATE DATABASE {APP_DB}\"))\n",
    "        # Optionally assign an owner:\n",
    "        # conn.execute(text(f\"ALTER DATABASE {APP_DB} OWNER TO {PG_USER}\"))\n",
    "\n",
    "# 2) Now connect to your actual app database\n",
    "app_url = f\"postgresql+psycopg://{PG_USER}:{PG_PASS}@{PG_HOST}:{PG_PORT}/{APP_DB}\"\n",
    "app_engine = create_engine(app_url)\n",
    "\n",
    "print(\"Database ready ‚úÖ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cc9fa41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission: 2 Alice Ahmed\n",
      "in_probation: True\n",
      "notice_period_days: 45\n",
      "created_at: 2025-10-29 13:34:17.703922+03:00 updated_at: 2025-10-29 13:34:17.703922+03:00\n",
      "updated_at after update: 2025-10-29 13:34:17.721702+03:00\n"
     ]
    }
   ],
   "source": [
    "# file: hr_copilot_models.py\n",
    "from datetime import date, datetime  # add datetime\n",
    "from typing import Optional\n",
    "from sqlalchemy import (\n",
    "    create_engine, text, MetaData, Table, Index, DDL, event,\n",
    "    Integer, String, Boolean, Date, TIMESTAMP, func, ForeignKey, Computed, Text, UniqueConstraint\n",
    ")\n",
    "from sqlalchemy.dialects import postgresql as psql\n",
    "from sqlalchemy.orm import DeclarativeBase, mapped_column, Mapped, relationship, Session\n",
    "from sqlalchemy.schema import ForeignKeyConstraint\n",
    "\n",
    "\n",
    "# ---- 0) Engine ----\n",
    "# Adjust to your settings\n",
    "DATABASE_URL = \"postgresql+psycopg://postgres:123@localhost:5432/appdb\"\n",
    "engine = create_engine(DATABASE_URL, echo=False, future=True)\n",
    "\n",
    "# ---- 1) Bootstrap objects that must exist before tables ----\n",
    "# Create role_t enum type if missing (safe via DO/EXCEPTION)\n",
    "BOOTSTRAP_ENUM = \"\"\"\n",
    "DO $$\n",
    "BEGIN\n",
    "  CREATE TYPE role_t AS ENUM ('super_user','hr','leader','chm','it','admin');\n",
    "EXCEPTION WHEN duplicate_object THEN NULL;\n",
    "END $$;\n",
    "\"\"\"\n",
    "\n",
    "# Create/replace the set_updated_at() trigger function\n",
    "BOOTSTRAP_FUNC = \"\"\"\n",
    "CREATE OR REPLACE FUNCTION set_updated_at() RETURNS trigger AS $$\n",
    "BEGIN\n",
    "  NEW.updated_at := now();\n",
    "  RETURN NEW;\n",
    "END;\n",
    "$$ LANGUAGE plpgsql;\n",
    "\"\"\"\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    conn.exec_driver_sql(BOOTSTRAP_ENUM)\n",
    "    conn.exec_driver_sql(BOOTSTRAP_FUNC)\n",
    "\n",
    "# We‚Äôll reference the already-created PostgreSQL enum\n",
    "role_t = psql.ENUM(\n",
    "    \"super_user\",\"hr\",\"leader\",\"chm\",\"it\",\"admin\",\n",
    "    name=\"role_t\", create_type=False\n",
    ")\n",
    "\n",
    "# ---- 2) ORM models / metadata ----\n",
    "class Base(DeclarativeBase):\n",
    "    metadata = MetaData()\n",
    "\n",
    "class User(Base):\n",
    "    __tablename__ = \"users\"\n",
    "\n",
    "    id: Mapped[int] = mapped_column(Integer, primary_key=True)\n",
    "    email: Mapped[str] = mapped_column(String(150), unique=True, nullable=False)\n",
    "    full_name: Mapped[str] = mapped_column(String(120), nullable=False)\n",
    "    role: Mapped[str] = mapped_column(role_t, nullable=False)\n",
    "    password_hash: Mapped[Optional[str]] = mapped_column(String, nullable=True)\n",
    "    is_active: Mapped[bool] = mapped_column(Boolean, nullable=False, server_default=text(\"TRUE\"))\n",
    "    created_at: Mapped[datetime] = mapped_column(TIMESTAMP(timezone=True), nullable=False, server_default=func.now())\n",
    "    hashed_password = mapped_column(String, nullable=False)\n",
    "\n",
    "\n",
    "class Submission(Base):\n",
    "    __tablename__ = \"submissions\"\n",
    "\n",
    "    id: Mapped[int] = mapped_column(Integer, primary_key=True)\n",
    "\n",
    "    employee_name: Mapped[str] = mapped_column(String(100), nullable=False)\n",
    "    employee_email: Mapped[str] = mapped_column(String(150), nullable=False)\n",
    "\n",
    "    joining_date: Mapped[date] = mapped_column(Date, nullable=False)\n",
    "    submission_date: Mapped[date] = mapped_column(Date, nullable=False, server_default=text(\"CURRENT_DATE\"))\n",
    "    last_working_day: Mapped[date] = mapped_column(Date, nullable=False)\n",
    "\n",
    "    resignation_status: Mapped[str] = mapped_column(String(30), nullable=False, server_default=text(\"'submitted'\"))\n",
    "    team_leader_reply: Mapped[Optional[bool]] = mapped_column(Boolean)\n",
    "    team_leader_notes: Mapped[Optional[str]] = mapped_column(Text)  # Text is fine for notes\n",
    "    chinese_head_reply: Mapped[Optional[bool]] = mapped_column(Boolean)\n",
    "    chinese_head_notes: Mapped[Optional[str]] = mapped_column(Text)\n",
    "\n",
    "    exit_interview_status: Mapped[str] = mapped_column(String(30), nullable=False, server_default=text(\"'not_scheduled'\"))\n",
    "    exit_interview_notes: Mapped[Optional[str]] = mapped_column(Text)\n",
    "\n",
    "    it_support_reply: Mapped[Optional[bool]] = mapped_column(Boolean)\n",
    "\n",
    "    vendor_mail_sent: Mapped[bool] = mapped_column(Boolean, nullable=False, server_default=text(\"FALSE\"))\n",
    "    medical_card_collected: Mapped[bool] = mapped_column(Boolean, nullable=False, server_default=text(\"FALSE\"))\n",
    "\n",
    "    in_probation: Mapped[bool] = mapped_column(\n",
    "        Boolean, Computed(\"(submission_date - joining_date) < 90\", persisted=True)\n",
    "    )\n",
    "    notice_period_days: Mapped[int] = mapped_column(\n",
    "        Integer, Computed(\"(last_working_day - submission_date)\", persisted=True)\n",
    "    )\n",
    "\n",
    "    created_at: Mapped[datetime] = mapped_column(TIMESTAMP(timezone=True), nullable=False, server_default=func.now())\n",
    "    updated_at: Mapped[datetime] = mapped_column(TIMESTAMP(timezone=True), nullable=False, server_default=func.now())\n",
    "\n",
    "    assets: Mapped[\"Assets\"] = relationship(\n",
    "        back_populates=\"submission\", uselist=False, cascade=\"all, delete-orphan\", passive_deletes=True\n",
    "    )\n",
    "\n",
    "    __table_args__ = (\n",
    "        Index(\"idx_submissions_status\", \"resignation_status\"),\n",
    "        Index(\"idx_submissions_employee_eml\", \"employee_email\"),\n",
    "    )\n",
    "\n",
    "\n",
    "class Assets(Base):\n",
    "    __tablename__ = \"assets\"\n",
    "\n",
    "    id: Mapped[int] = mapped_column(Integer, primary_key=True)\n",
    "    res_id: Mapped[int] = mapped_column(Integer, nullable=False)\n",
    "\n",
    "    laptop: Mapped[Optional[bool]] = mapped_column(Boolean)\n",
    "    mouse: Mapped[Optional[bool]] = mapped_column(Boolean)\n",
    "    headphones: Mapped[Optional[bool]] = mapped_column(Boolean)\n",
    "    others: Mapped[Optional[str]] = mapped_column(Text)\n",
    "    approved: Mapped[Optional[bool]] = mapped_column(Boolean)\n",
    "\n",
    "    created_at: Mapped[datetime] = mapped_column(TIMESTAMP(timezone=True), nullable=False, server_default=func.now())\n",
    "    updated_at: Mapped[datetime] = mapped_column(TIMESTAMP(timezone=True), nullable=False, server_default=func.now())\n",
    "\n",
    "    __table_args__ = (\n",
    "        ForeignKeyConstraint([\"res_id\"], [\"submissions.id\"], deferrable=True, initially=\"DEFERRED\"),\n",
    "        UniqueConstraint(\"res_id\", name=\"uq_assets_res_id\"),  # enforces one-to-one at DB level\n",
    "        Index(\"idx_assets_res_id\", \"res_id\"),\n",
    "    )\n",
    "\n",
    "    submission: Mapped[\"Submission\"] = relationship(back_populates=\"assets\", single_parent=True)\n",
    "\n",
    "\n",
    "# ---- 3) Create tables ----\n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "# ---- 4) Triggers: keep updated_at fresh on UPDATE (matches your DDL) ----\n",
    "# Drop+Create triggers for submissions\n",
    "submissions_tbl: Table = Submission.__table__\n",
    "assets_tbl: Table = Assets.__table__\n",
    "\n",
    "trg_drop_create_submissions = DDL(\"\"\"\n",
    "DROP TRIGGER IF EXISTS trg_submissions_updated ON submissions;\n",
    "CREATE TRIGGER trg_submissions_updated\n",
    "BEFORE UPDATE ON submissions\n",
    "FOR EACH ROW EXECUTE FUNCTION set_updated_at();\n",
    "\"\"\")\n",
    "\n",
    "trg_drop_create_assets = DDL(\"\"\"\n",
    "DROP TRIGGER IF EXISTS trg_assets_updated ON assets;\n",
    "CREATE TRIGGER trg_assets_updated\n",
    "BEFORE UPDATE ON assets\n",
    "FOR EACH ROW EXECUTE FUNCTION set_updated_at();\n",
    "\"\"\")\n",
    "\n",
    "# Ensure triggers exist after (re)creating tables\n",
    "event.listen(submissions_tbl, \"after_create\", trg_drop_create_submissions)\n",
    "event.listen(assets_tbl, \"after_create\", trg_drop_create_assets)\n",
    "\n",
    "# (Re-)run the trigger DDL now that tables exist\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(\"DROP TRIGGER IF EXISTS trg_submissions_updated ON submissions\"))\n",
    "    conn.execute(text(\"CREATE TRIGGER trg_submissions_updated BEFORE UPDATE ON submissions FOR EACH ROW EXECUTE FUNCTION set_updated_at()\"))\n",
    "    conn.execute(text(\"DROP TRIGGER IF EXISTS trg_assets_updated ON assets\"))\n",
    "    conn.execute(text(\"CREATE TRIGGER trg_assets_updated BEFORE UPDATE ON assets FOR EACH ROW EXECUTE FUNCTION set_updated_at()\"))\n",
    "\n",
    "# ---- 5) Tiny demo: insert / query / see generated columns ----\n",
    "if __name__ == \"__main__\":\n",
    "    with Session(engine) as s:\n",
    "        # create a submission\n",
    "        sub = Submission(\n",
    "            employee_name=\"Alice Ahmed\",\n",
    "            employee_email=\"alice@example.com\",\n",
    "            joining_date=date(2025, 8, 1),\n",
    "            submission_date=date(2025, 10, 1),\n",
    "            last_working_day=date(2025, 11, 15),\n",
    "            resignation_status=\"submitted\"\n",
    "        )\n",
    "        s.add(sub)\n",
    "        s.flush()  # get sub.id\n",
    "\n",
    "        # add assets (one-to-one)\n",
    "        assets = Assets(res_id=sub.id, laptop=True, mouse=True, headphones=False, approved=None, others=\"Returned badge\")\n",
    "        s.add(assets)\n",
    "        s.commit()\n",
    "\n",
    "        # query + show generated columns and timestamps\n",
    "        fresh = s.get(Submission, sub.id)\n",
    "        print(\"Submission:\", fresh.id, fresh.employee_name)\n",
    "        print(\"in_probation:\", fresh.in_probation)          # boolean from generated column\n",
    "        print(\"notice_period_days:\", fresh.notice_period_days)\n",
    "        print(\"created_at:\", fresh.created_at, \"updated_at:\", fresh.updated_at)\n",
    "\n",
    "        # trigger demo: update notes -> updated_at changes\n",
    "        fresh.team_leader_notes = \"Looks good.\"\n",
    "        s.commit()\n",
    "        s.refresh(fresh)\n",
    "        print(\"updated_at after update:\", fresh.updated_at)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae0cfac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema created/updated successfully.\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "DATABASE_URL = \"postgresql+psycopg://postgres:123@localhost:5432/appdb\"\n",
    "engine = create_engine(DATABASE_URL, echo=False, future=True)\n",
    "\n",
    "stmts = [\n",
    "    # --- tables ---\n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS exit_interviews (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        submission_id INTEGER UNIQUE NOT NULL\n",
    "            REFERENCES submissions(id) ON DELETE CASCADE,\n",
    "\n",
    "        -- Scheduling Information\n",
    "        scheduled_date TIMESTAMP,\n",
    "        scheduled_time VARCHAR(10),  -- HH:MM format\n",
    "        location VARCHAR(200),\n",
    "        interviewer VARCHAR(100),\n",
    "\n",
    "        -- Interview Details\n",
    "        interview_completed BOOLEAN DEFAULT FALSE,\n",
    "        interview_feedback TEXT,\n",
    "        interview_rating INTEGER,  -- 1-5 scale\n",
    "        interview_type VARCHAR(50),  -- in-person, virtual, phone\n",
    "\n",
    "        -- Follow-up Actions\n",
    "        hr_notes TEXT,\n",
    "        it_notification_sent BOOLEAN DEFAULT FALSE,\n",
    "\n",
    "        -- Timestamps\n",
    "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "        interview_completed_at TIMESTAMP\n",
    "    );\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS exit_interview_reminders (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        exit_interview_id INTEGER NOT NULL\n",
    "            REFERENCES exit_interviews(id) ON DELETE CASCADE,\n",
    "\n",
    "        -- Reminder Type\n",
    "        reminder_type VARCHAR(50) NOT NULL,  -- schedule_interview, submit_feedback, employee_reminder\n",
    "\n",
    "        -- Status\n",
    "        sent BOOLEAN DEFAULT FALSE,\n",
    "        sent_at TIMESTAMP,\n",
    "        scheduled_for TIMESTAMP NOT NULL,\n",
    "\n",
    "        -- Email details\n",
    "        recipient_email VARCHAR(150) NOT NULL,\n",
    "        recipient_name VARCHAR(100) NOT NULL,\n",
    "\n",
    "        -- Response tracking\n",
    "        responded BOOLEAN DEFAULT FALSE,\n",
    "        responded_at TIMESTAMP,\n",
    "\n",
    "        -- Timestamps\n",
    "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    );\n",
    "    \"\"\",\n",
    "\n",
    "    # --- indexes ---\n",
    "    \"CREATE INDEX IF NOT EXISTS idx_exit_interviews_submission_id ON exit_interviews(submission_id);\",\n",
    "    \"CREATE INDEX IF NOT EXISTS idx_exit_interviews_scheduled_date ON exit_interviews(scheduled_date);\",\n",
    "    \"CREATE INDEX IF NOT EXISTS idx_exit_interview_reminders_interview_id ON exit_interview_reminders(exit_interview_id);\",\n",
    "    \"CREATE INDEX IF NOT EXISTS idx_exit_interview_reminders_scheduled_for ON exit_interview_reminders(scheduled_for);\",\n",
    "\n",
    "    # --- trigger function (separate statement because it includes $$...$$ with semicolons inside) ---\n",
    "    \"\"\"\n",
    "    CREATE OR REPLACE FUNCTION update_updated_at_column()\n",
    "    RETURNS TRIGGER AS $$\n",
    "    BEGIN\n",
    "        NEW.updated_at = CURRENT_TIMESTAMP;\n",
    "        RETURN NEW;\n",
    "    END;\n",
    "    $$ LANGUAGE plpgsql;\n",
    "    \"\"\",\n",
    "\n",
    "    # --- triggers (drop-if-exists for idempotency, then create) ---\n",
    "    \"DROP TRIGGER IF EXISTS update_exit_interviews_updated_at ON exit_interviews;\",\n",
    "    \"\"\"\n",
    "    CREATE TRIGGER update_exit_interviews_updated_at\n",
    "        BEFORE UPDATE ON exit_interviews\n",
    "        FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();\n",
    "    \"\"\",\n",
    "    \"DROP TRIGGER IF EXISTS update_exit_interview_reminders_updated_at ON exit_interview_reminders;\",\n",
    "    \"\"\"\n",
    "    CREATE TRIGGER update_exit_interview_reminders_updated_at\n",
    "        BEFORE UPDATE ON exit_interview_reminders\n",
    "        FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "# Run everything in one transaction\n",
    "with engine.begin() as conn:\n",
    "    for sql in stmts:\n",
    "        conn.exec_driver_sql(sql)\n",
    "\n",
    "print(\"Schema created/updated successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "097512fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "employee_name\n",
      "employee_email\n",
      "joining_date\n",
      "submission_date\n",
      "last_working_day\n",
      "resignation_status\n",
      "team_leader_reply\n",
      "team_leader_notes\n",
      "chinese_head_reply\n",
      "chinese_head_notes\n",
      "exit_interview_status\n",
      "exit_interview_notes\n",
      "it_support_reply\n",
      "vendor_mail_sent\n",
      "medical_card_collected\n",
      "in_probation\n",
      "notice_period_days\n",
      "created_at\n",
      "updated_at\n",
      "last_reminded_at\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import inspect\n",
    "\n",
    "inspector = inspect(engine)\n",
    "for column in inspector.get_columns(\"submissions\", schema=\"public\"):\n",
    "    print(column[\"name\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de5c55be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 200\n",
      "Response: {'employee_name': 'Youssef Khalifa', 'employee_email': 'kalam11@company.com', 'joining_date': '2024-01-01T00:00:00', 'submission_date': '2024-11-02T00:00:00', 'last_working_day': '2024-12-31T00:00:00', 'id': 65, 'resignation_status': 'submitted', 'exit_interview_status': 'not_scheduled', 'team_leader_reply': None, 'chinese_head_reply': None, 'it_support_reply': None, 'medical_card_collected': False, 'vendor_mail_sent': False, 'team_leader_notes': None, 'chinese_head_notes': None, 'exit_interview_notes': None, 'in_probation': False, 'notice_period_days': 59, 'created_at': '2025-11-02T11:47:25.312406Z', 'updated_at': '2025-11-02T11:47:25.312406Z'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.post(\"http://localhost:8000/api/submission\",\n",
    "                          json={\n",
    "      \"employee_name\": \"Youssef Khalifa\",\n",
    "      \"employee_email\": \"kalam11@company.com\",\n",
    "      \"joining_date\": \"2024-01-01T00:00:00\",\n",
    "      \"submission_date\": \"2024-11-02T00:00:00\",\n",
    "      \"last_working_day\": \"2024-12-31T00:00:00\",\n",
    "      \"department\": \"AIPB\",\n",
    "      \"position\": \"AIBP\",\n",
    "      \"leader_name\": \"Youssef Khalifa\",\n",
    "      \"reason\": \"Test with leader name only\"\n",
    "  })\n",
    "\n",
    "print(f\"Status: {response.status_code}\")\n",
    "print(f\"Response: {response.json()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b436f42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è  PREPARING TO EMPTY SUBMISSIONS TABLE\n",
      "==================================================\n",
      "[DB] Database session closed in 0.000s\n",
      "[DB] Database session obtained in 0.000s\n",
      "[DB] Connection checked out from pool\n",
      "üìä Current Records Count:\n",
      "  Submissions: 1\n",
      "  Assets: 0\n",
      "  Exit Interviews: 0\n",
      "  Interview Reminders: 0\n",
      "\n",
      "‚ö†Ô∏è  WARNING: About to delete ALL submission records!\n",
      "‚úÖ Deleted interview reminders\n",
      "‚úÖ Deleted exit interviews\n",
      "‚úÖ Deleted assets\n",
      "‚úÖ Deleted submissions\n",
      "[DB] Connection returned to pool\n",
      "\n",
      "üéâ SUCCESS! All submission records have been deleted.\n",
      "[DB] Connection checked out from pool\n",
      "üìä Remaining submissions: 0\n",
      "[DB] Connection returned to pool\n",
      "üîê Database connection closed\n",
      "==================================================\n",
      "‚úÖ Operation completed!\n"
     ]
    }
   ],
   "source": [
    "# Empty the submissions table entirely\n",
    "# WARNING: This will delete ALL records permanently!\n",
    "\n",
    "import pandas as pd\n",
    "from app.database import engine, get_db\n",
    "from app.models.submission import Submission\n",
    "from app.models.asset import Asset\n",
    "from app.models.exit_interview import ExitInterview, ExitInterviewReminder\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import text\n",
    "\n",
    "print(\"üóëÔ∏è  PREPARING TO EMPTY SUBMISSIONS TABLE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Get database session\n",
    "db_gen = get_db()\n",
    "db = next(db_gen)\n",
    "\n",
    "try:\n",
    "    # Count records before deletion\n",
    "    submissions_count = db.query(Submission).count()\n",
    "    assets_count = db.query(Asset).count()\n",
    "    interviews_count = db.query(ExitInterview).count()\n",
    "    reminders_count = db.query(ExitInterviewReminder).count()\n",
    "\n",
    "    print(f\"üìä Current Records Count:\")\n",
    "    print(f\"  Submissions: {submissions_count}\")\n",
    "    print(f\"  Assets: {assets_count}\")\n",
    "    print(f\"  Exit Interviews: {interviews_count}\")\n",
    "    print(f\"  Interview Reminders: {reminders_count}\")\n",
    "\n",
    "    if submissions_count == 0:\n",
    "        print(\"‚úÖ Submissions table is already empty!\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  WARNING: About to delete ALL submission records!\")\n",
    "\n",
    "        # Delete all records in correct order (respecting foreign keys)\n",
    "\n",
    "        # 1. Delete interview reminders first\n",
    "        db.query(ExitInterviewReminder).delete()\n",
    "        print(\"‚úÖ Deleted interview reminders\")\n",
    "\n",
    "        # 2. Delete exit interviews\n",
    "        db.query(ExitInterview).delete()\n",
    "        print(\"‚úÖ Deleted exit interviews\")\n",
    "\n",
    "        # 3. Delete assets\n",
    "        db.query(Asset).delete()\n",
    "        print(\"‚úÖ Deleted assets\")\n",
    "\n",
    "        # 4. Delete submissions last\n",
    "        db.query(Submission).delete()\n",
    "        print(\"‚úÖ Deleted submissions\")\n",
    "\n",
    "        # Commit the changes\n",
    "        db.commit()\n",
    "\n",
    "        print(\"\\nüéâ SUCCESS! All submission records have been deleted.\")\n",
    "\n",
    "        # Verify deletion\n",
    "        remaining_submissions = db.query(Submission).count()\n",
    "        print(f\"üìä Remaining submissions: {remaining_submissions}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {str(e)}\")\n",
    "    db.rollback()\n",
    "finally:\n",
    "    db.close()\n",
    "    print(\"üîê Database connection closed\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"‚úÖ Operation completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc87c130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "awage0yuh38",
   "source": "# üß™ Test Submission Insertion Cells\n\nUse these cells to quickly insert test submissions into the database for testing workflows.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "de9f62lgzjw",
   "source": "# Cell 1: Setup - Import required modules\nimport requests\nfrom datetime import datetime, timedelta\nimport json\n\nBASE_URL = \"http://localhost:8000\"\n\n# Login and get token\ndef get_auth_token():\n    response = requests.post(\n        f\"{BASE_URL}/api/auth/login\",\n        json={\"email\": \"hr@company.com\", \"password\": \"hr123456\"}\n    )\n    if response.status_code == 200:\n        return response.json()['access_token']\n    else:\n        raise Exception(f\"Login failed: {response.status_code} - {response.text}\")\n\n# Get authentication token\ntoken = get_auth_token()\nheaders = {\"Authorization\": f\"Bearer {token}\"}\n\nprint(\"‚úÖ Authentication successful!\")\nprint(f\"Token: {token[:30]}...\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "5lqeywmoyyf",
   "source": "# Cell 2: Insert a SINGLE test submission\nfrom datetime import datetime, timedelta\n\n# Calculate dates\njoining_date = (datetime.now() - timedelta(days=365)).strftime(\"%Y-%m-%d\")\nsubmission_date = datetime.now().strftime(\"%Y-%m-%d\")\nlast_working_day = (datetime.now() + timedelta(days=30)).strftime(\"%Y-%m-%d\")\n\nsubmission = {\n    \"employee_name\": \"John Doe\",\n    \"employee_email\": \"john.doe@company.com\",\n    \"employee_id\": \"EMP001\",\n    \"joining_date\": joining_date,\n    \"submission_date\": submission_date,\n    \"last_working_day\": last_working_day,\n    \"resignation_reason\": \"Career Growth\",\n    \"notice_period_days\": 30,\n    \"department\": \"Engineering\",\n    \"position\": \"Software Engineer\",\n    \"team_leader_email\": \"leader@company.com\",\n    \"chm_email\": \"chm@company.com\"\n}\n\nresponse = requests.post(f\"{BASE_URL}/api/submissions\", json=submission, headers=headers)\n\nif response.status_code in [200, 201]:\n    result = response.json()\n    print(\"‚úÖ Submission created successfully!\")\n    print(f\"   ID: {result['id']}\")\n    print(f\"   Employee: {result['employee_name']}\")\n    print(f\"   Status: {result['resignation_status']}\")\n    print(f\"   Notice Period: {result['notice_period_days']} days\")\nelse:\n    print(f\"‚ùå Failed: {response.status_code}\")\n    print(f\"   Response: {response.text}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "4myuja16nxc",
   "source": "# Cell 3: Insert MULTIPLE test submissions at once\nimport random\n\n# Sample data for realistic submissions\nfirst_names = [\"Alice\", \"Bob\", \"Charlie\", \"Diana\", \"Edward\", \"Fiona\", \"George\", \"Hannah\", \"Ian\", \"Julia\"]\nlast_names = [\"Smith\", \"Johnson\", \"Williams\", \"Brown\", \"Jones\", \"Garcia\", \"Miller\", \"Davis\", \"Rodriguez\", \"Martinez\"]\ndepartments = [\"Engineering\", \"Sales\", \"Marketing\", \"HR\", \"Finance\", \"Operations\", \"IT\", \"Customer Support\"]\npositions = [\"Manager\", \"Developer\", \"Analyst\", \"Coordinator\", \"Specialist\", \"Engineer\", \"Associate\", \"Lead\"]\nreasons = [\"Career Growth\", \"Personal Reasons\", \"Better Opportunity\", \"Relocation\", \"Further Education\"]\n\n# Number of submissions to create\nnum_submissions = 5\n\ncreated_submissions = []\n\nprint(f\"Creating {num_submissions} test submissions...\\n\")\n\nfor i in range(num_submissions):\n    # Random dates\n    days_since_joining = random.randint(100, 800)\n    notice_days = random.choice([15, 30, 45, 60])\n    \n    joining_date = (datetime.now() - timedelta(days=days_since_joining)).strftime(\"%Y-%m-%d\")\n    submission_date = datetime.now().strftime(\"%Y-%m-%d\")\n    last_working_day = (datetime.now() + timedelta(days=notice_days)).strftime(\"%Y-%m-%d\")\n    \n    # Random employee data\n    first_name = random.choice(first_names)\n    last_name = random.choice(last_names)\n    emp_name = f\"{first_name} {last_name}\"\n    emp_email = f\"{first_name.lower()}.{last_name.lower()}@company.com\"\n    emp_id = f\"EMP{random.randint(1000, 9999)}\"\n    \n    submission = {\n        \"employee_name\": emp_name,\n        \"employee_email\": emp_email,\n        \"employee_id\": emp_id,\n        \"joining_date\": joining_date,\n        \"submission_date\": submission_date,\n        \"last_working_day\": last_working_day,\n        \"resignation_reason\": random.choice(reasons),\n        \"notice_period_days\": notice_days,\n        \"department\": random.choice(departments),\n        \"position\": random.choice(positions),\n        \"team_leader_email\": \"leader@company.com\",\n        \"chm_email\": \"chm@company.com\"\n    }\n    \n    response = requests.post(f\"{BASE_URL}/api/submissions\", json=submission, headers=headers)\n    \n    if response.status_code in [200, 201]:\n        result = response.json()\n        created_submissions.append(result)\n        print(f\"‚úÖ [{i+1}/{num_submissions}] {emp_name} - ID: {result['id']} - {result['department']}\")\n    else:\n        print(f\"‚ùå [{i+1}/{num_submissions}] Failed for {emp_name}: {response.status_code}\")\n\nprint(f\"\\nüéâ Created {len(created_submissions)} submissions successfully!\")\nprint(f\"üìä Summary:\")\nprint(f\"   - Total Created: {len(created_submissions)}\")\nprint(f\"   - Departments: {len(set(s['department'] for s in created_submissions))}\")\nprint(f\"   - Avg Notice Period: {sum(s['notice_period_days'] for s in created_submissions) / len(created_submissions):.0f} days\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "2vs8v8mzmvq",
   "source": "# Cell 4: View all submissions (display in a nice table format)\nimport pandas as pd\n\nresponse = requests.get(f\"{BASE_URL}/api/submissions\", headers=headers)\n\nif response.status_code == 200:\n    submissions = response.json()\n    \n    if submissions:\n        # Convert to DataFrame for nice display\n        df = pd.DataFrame(submissions)\n        \n        # Select key columns\n        display_cols = ['id', 'employee_name', 'employee_email', 'department', \n                       'resignation_status', 'exit_interview_status', \n                       'notice_period_days', 'last_working_day']\n        \n        # Filter to existing columns\n        display_cols = [col for col in display_cols if col in df.columns]\n        \n        print(f\"üìã Total Submissions: {len(submissions)}\\n\")\n        print(df[display_cols].to_string(index=False))\n        \n        # Show statistics\n        print(f\"\\nüìä Statistics:\")\n        print(f\"   - Total: {len(submissions)}\")\n        if 'resignation_status' in df.columns:\n            print(f\"   - Status breakdown:\")\n            for status, count in df['resignation_status'].value_counts().items():\n                print(f\"     ‚Ä¢ {status}: {count}\")\n        if 'department' in df.columns:\n            print(f\"   - Departments: {df['department'].nunique()}\")\n    else:\n        print(\"üì≠ No submissions found\")\nelse:\n    print(f\"‚ùå Failed to retrieve submissions: {response.status_code}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "xy5trpd168l",
   "source": "# Cell 5: Test COMPLETE WORKFLOW (Submission ‚Üí Exit Interview ‚Üí Asset)\nfrom datetime import datetime, timedelta\n\nprint(\"üîÑ Testing Complete Workflow\\n\")\nprint(\"=\" * 60)\n\n# Step 1: Create Submission\nprint(\"\\nüìù Step 1: Creating Submission...\")\nsubmission_data = {\n    \"employee_name\": \"Workflow Test Employee\",\n    \"employee_email\": \"workflow.test@company.com\",\n    \"employee_id\": \"EMP9999\",\n    \"joining_date\": (datetime.now() - timedelta(days=200)).strftime(\"%Y-%m-%d\"),\n    \"submission_date\": datetime.now().strftime(\"%Y-%m-%d\"),\n    \"last_working_day\": (datetime.now() + timedelta(days=30)).strftime(\"%Y-%m-%d\"),\n    \"resignation_reason\": \"Testing Complete Workflow\",\n    \"notice_period_days\": 30,\n    \"department\": \"IT\",\n    \"position\": \"Test Engineer\",\n    \"team_leader_email\": \"leader@company.com\",\n    \"chm_email\": \"chm@company.com\"\n}\n\nresponse = requests.post(f\"{BASE_URL}/api/submissions\", json=submission_data, headers=headers)\nif response.status_code in [200, 201]:\n    submission = response.json()\n    submission_id = submission['id']\n    print(f\"   ‚úÖ Submission created - ID: {submission_id}\")\nelse:\n    print(f\"   ‚ùå Failed: {response.status_code}\")\n    submission_id = None\n\n# Step 2: Schedule Exit Interview (if submission created)\nif submission_id:\n    print(\"\\nüìÖ Step 2: Scheduling Exit Interview...\")\n    interview_data = {\n        \"submission_id\": submission_id,\n        \"scheduled_date\": (datetime.now() + timedelta(days=7)).strftime(\"%Y-%m-%d\"),\n        \"scheduled_time\": \"14:00\",\n        \"location\": \"Conference Room A\",\n        \"interviewer\": \"HR Manager\"\n    }\n    \n    response = requests.post(f\"{BASE_URL}/api/exit-interviews/schedule\", \n                            json=interview_data, headers=headers)\n    if response.status_code in [200, 201]:\n        interview = response.json()\n        interview_id = interview['id']\n        print(f\"   ‚úÖ Exit interview scheduled - ID: {interview_id}\")\n        print(f\"   üìÜ Date: {interview['scheduled_date']} at {interview['scheduled_time']}\")\n    else:\n        print(f\"   ‚ùå Failed: {response.status_code} - {response.text}\")\n        interview_id = None\nelse:\n    interview_id = None\n\n# Step 3: Create Asset Record (if submission created)\nif submission_id:\n    print(\"\\nüíª Step 3: Creating Asset Record...\")\n    asset_data = {\n        \"laptop_serial\": \"TEST-LAPTOP-123\",\n        \"laptop_model\": \"MacBook Pro 16-inch\",\n        \"mouse\": True,\n        \"keyboard\": True,\n        \"headphones\": True,\n        \"monitor\": True,\n        \"monitor_serial\": \"TEST-MON-456\",\n        \"other_items\": \"USB-C cables, charger\",\n        \"collection_status\": \"pending\",\n        \"collected_by\": \"\",\n        \"it_approval_status\": \"pending\",\n        \"notes\": \"Test asset record\"\n    }\n    \n    response = requests.post(f\"{BASE_URL}/api/assets/submissions/{submission_id}/assets\",\n                            json=asset_data, headers=headers)\n    if response.status_code in [200, 201]:\n        asset = response.json()\n        asset_id = asset['id']\n        print(f\"   ‚úÖ Asset record created - ID: {asset_id}\")\n        print(f\"   üíª Laptop: {asset['laptop_model']}\")\n        accessories = []\n        if asset['mouse']: accessories.append('Mouse')\n        if asset['keyboard']: accessories.append('Keyboard')\n        if asset['headphones']: accessories.append('Headphones')\n        if asset['monitor']: accessories.append('Monitor')\n        print(f\"   üì¶ Accessories: {', '.join(accessories)}\")\n    else:\n        print(f\"   ‚ùå Failed: {response.status_code} - {response.text}\")\n        asset_id = None\nelse:\n    asset_id = None\n\n# Summary\nprint(\"\\n\" + \"=\" * 60)\nprint(\"üìä Workflow Test Summary:\")\nprint(f\"   Submission ID: {submission_id if submission_id else '‚ùå Not created'}\")\nprint(f\"   Interview ID:  {interview_id if interview_id else '‚ùå Not created'}\")\nprint(f\"   Asset ID:      {asset_id if asset_id else '‚ùå Not created'}\")\n\nif submission_id and interview_id and asset_id:\n    print(\"\\nüéâ Complete workflow test PASSED! All components created successfully.\")\nelse:\n    print(\"\\n‚ö†Ô∏è  Workflow test incomplete - check errors above\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "2ataffyfcy8",
   "source": "# Cell 6: Delete test submissions (cleanup)\n# WARNING: This will delete ALL submissions! Use with caution.\n\nprint(\"üóëÔ∏è  CLEANUP: Deleting all test submissions\")\nprint(\"‚ö†Ô∏è  WARNING: This will delete ALL submissions!\")\nprint(\"\\nPress Enter to continue or Ctrl+C to cancel...\")\n# input()  # Uncomment to require confirmation\n\nresponse = requests.get(f\"{BASE_URL}/api/submissions\", headers=headers)\n\nif response.status_code == 200:\n    submissions = response.json()\n    \n    if not submissions:\n        print(\"‚úÖ No submissions to delete\")\n    else:\n        print(f\"\\nDeleting {len(submissions)} submission(s)...\\n\")\n        \n        deleted_count = 0\n        failed_count = 0\n        \n        for sub in submissions:\n            delete_response = requests.delete(\n                f\"{BASE_URL}/api/submissions/{sub['id']}\", \n                headers=headers\n            )\n            \n            if delete_response.status_code == 200:\n                deleted_count += 1\n                print(f\"‚úÖ Deleted: {sub['employee_name']} (ID: {sub['id']})\")\n            else:\n                failed_count += 1\n                print(f\"‚ùå Failed to delete ID {sub['id']}: {delete_response.status_code}\")\n        \n        print(f\"\\nüìä Cleanup Summary:\")\n        print(f\"   - Deleted: {deleted_count}\")\n        print(f\"   - Failed: {failed_count}\")\n        print(f\"   - Total: {len(submissions)}\")\n        \n        if deleted_count == len(submissions):\n            print(\"\\nüéâ All submissions deleted successfully!\")\n        else:\n            print(\"\\n‚ö†Ô∏è  Some deletions failed - check errors above\")\nelse:\n    print(f\"‚ùå Failed to retrieve submissions: {response.status_code}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HR_Resignation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}